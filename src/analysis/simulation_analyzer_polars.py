import logging
import os
import shutil
from glob import glob

import numpy as np
import polars as pl
from rich.logging import RichHandler

from src.analysis.constants import EVENTS, YEARLY_COST_EFFECTIVENESS_COLUMN_ORDER
from src.analysis.utils_polars import (
    unfurl_and_tally_chronic_events,
    unfurl_and_tally_events, unfurl_and_tally_risk_factors, unfurl_and_tally_risk_factors_surgery,
)
from src.directory_paths import (
    ANALYSIS_OUTPUT_PATH,
    POPULATION_OUTPUT_PATH
)
from src.simulation.utils_polars import make_directory

logging.basicConfig(level=logging.INFO, format="%(message)s", handlers=[RichHandler()])


class SimulationAnalyzerPolars:
    """
    Manages the analysis of the simulation results.

    Attributes
    ----------
    scenario : dict
        Scenario to be analyzed
    uuid : str
        UUID of the user
    scenario_name : str
        Name of the scenario
    equation_set : str
        Equation set to be used
    intervention_cost : int
        Cost of the intervention
    simulation_results_path : str
        Directory containing the simulation results
    analysis_output_path : str
        Path to the analysis output directory
    analysis_data_path : str
        Path to the analysis data directory
    events : list
        List of events
    debug : bool
        Flag indicating whether to write debug files

    Methods
    -------
    run()
        Run the analysis.
    cleanup()
        Clean up the analysis output directory.
    _setup_directories()
        Create the analysis output and data directories.
    _fix_non_compliers()
        Fix non-compliers in the intervention run by replacing them with corresponding individuals from the non-intervention run.
    _swap_non_compliant_rows(intervention_df, non_intervention_df)
        Swap non-compliant rows from intervention run with corresponding rows from non-intervention run.
    _write_debug_files_to_csv(intervention_df, swapped_intervention_df, non_intervention_df, padded_iteration)
        Write the intervention, swapped intervention, and non-intervention DataFrames to CSV files.
    _combine_and_collapse()
        For each parquet file generated by the simulation, total the results for a few specific metrics.
    _combine_and_rechunk(data)
        Combine the DataFrames and rechunk the resulting DataFrame.
    _process_data(data, run_type, is_intervention)
        Process the simulation results to extract the desired metrics.
    _set_incidence(df, run_type, is_intervention)
        Set the incidence of chronic and acute events.
    _get_incidence_events()
        Get the chronic and acute events for the given diabetes type.
    _set_yearly_cost_effectiveness(df, run_type, is_intervention)
        Set the yearly cost-effectiveness metrics.
    _set_cost_effectiveness(df, run_type, is_intervention)
        Set the cost-effectiveness metrics.
    _order_columns(df)
        Order the columns in the DataFrame so that the first 3 columns are group, intervention, step.
    _create_data_tables(combined_dataframes)
        Create the CSV data tables.
    _record_incidence(df)
        Record the incidence of chronic and acute events.
    _record_prevalence(df)
        Record the prevalence of chronic and acute events.
    _record_cost_effectiveness(df)
        Record the cost-effectiveness metrics.
    _calculate_cost_effectiveness_increments(run, run_group, population_size)
        Calculate the cost-effectiveness increments for a given run.
    _transposed_column_name_generator()
        Generate the column names for the transposed cost-effectiveness DataFrame.
    _get_cost_effectiveness_column_order()
        Get the column order for the cost-effectiveness metrics.
    _record_yearly_cost_effectiveness(df)
        Record the yearly cost-effectiveness metrics.
    _calculate_yearly_cost_effectiveness_increments(run, run_group, population_size)
        Calculate the yearly cost-effectiveness increments for a given run.
    _fix_uneven_runs(df)
        Fix uneven runs in the DataFrame.
    """

    __slots__ = (
        "scenario",
        "uuid",
        "scenario_name",
        "equation_set",
        "intervention_cost",
        "population_results_path",
        "simulation_results_path",
        "analysis_output_path",
        "events",
        "debug",
    )

    def __init__(self, scenario: dict, uuid: str, debug: bool = False):
        self.scenario = scenario
        self.uuid = uuid
        self.scenario_name = scenario["scenario_name"]
        self.equation_set = scenario["diabetes_type"]
        self.intervention_cost = 0
        self.population_results_path = os.path.join(
            POPULATION_OUTPUT_PATH, uuid
        )
        self.simulation_results_path = os.path.join(
            ANALYSIS_OUTPUT_PATH, uuid, "data"
        )
        self.analysis_output_path = os.path.join(
            ANALYSIS_OUTPUT_PATH, uuid
        )
        self.events = EVENTS[self.equation_set]
        self.debug = debug

    def run(self) -> None:
        """
        Run the analysis.

        Returns
        -------
        None
        """
        self._setup_directories()
        self._fix_non_compliers()
        combined_dataframes = self._combine_and_collapse()
        self._create_data_tables(combined_dataframes)
        self.cleanup()

    def _setup_directories(self) -> None:
        """
        Create the analysis output and data directories.

        Returns
        -------
        None
        """
        make_directory(self.analysis_output_path)
        make_directory(self.simulation_results_path)

    def _fix_non_compliers(self) -> None:
        """
        Fix non-compliers in the intervention run by replacing them with corresponding individuals from the non-intervention run.

        This is done for each iteration of the simulation. Once the non-compliers are replaced, the intervention run is saved
        to ``self.simulation_results_path``. The replacement is done at the behest of the PI.

        Returns
        -------
        None
        """
        simulation_result_files = os.listdir(self.simulation_results_path)

        for iteration in range(1, self.scenario["iterations"] + 1):
            padded_iteration = str(iteration).rjust(4, "0")

            intervention_file_name = f"{self.scenario['scenario_name']}__intervention--{padded_iteration}.parquet"
            non_intervention_file_name = f"{self.scenario['scenario_name']}__non-intervention--{padded_iteration}.parquet"

            if intervention_file_name not in simulation_result_files:
                raise FileNotFoundError(
                    f"Intervention file {intervention_file_name} not found"
                )
            if non_intervention_file_name not in simulation_result_files:
                raise FileNotFoundError(
                    f"Non-intervention file {non_intervention_file_name} not found"
                )

            intervention_df = pl.read_parquet(
                os.path.join(self.simulation_results_path, intervention_file_name)
            )
            non_intervention_df = pl.read_parquet(
                os.path.join(
                    self.simulation_results_path, non_intervention_file_name
                )
            )

            swapped_intervention_df = self._swap_non_compliant_rows(
                intervention_df, non_intervention_df
            )

            if self.debug:
                self._write_debug_files_to_csv(
                    intervention_df,
                    swapped_intervention_df,
                    non_intervention_df,
                    padded_iteration,
                )

            swapped_intervention_df.write_parquet(
                os.path.join(self.simulation_results_path, intervention_file_name)
            )
            non_intervention_df.write_parquet(
                os.path.join(self.simulation_results_path, non_intervention_file_name)
            )

    def _swap_non_compliant_rows(
            self, intervention_df: pl.DataFrame, non_intervention_df: pl.DataFrame
    ) -> pl.DataFrame:
        """
        Swap non-compliant rows from intervention run with corresponding rows from non-intervention run.

        Parameters
        ----------
        intervention_df : pl.DataFrame
            DataFrame from intervention run
        non_intervention_df : pl.DataFrame
            DataFrame from non-intervention run

        Returns
        -------
        pl.DataFrame
            DataFrame with non-compliant rows swapped
        """
        indexed_intervention_df = intervention_df.with_row_index("agent_index")
        indexed_non_intervention_df = non_intervention_df.with_row_index("agent_index")

        interventions = ["glycemic", "cholesterol", "bp", "lifestyle"]
        all_non_complying_rows = set()
        for intervention in interventions:
            if (
                    intervention_column := f"{intervention}_non_compliant"
            ) in indexed_intervention_df.columns:
                non_complier_rows = (
                    indexed_intervention_df.filter(pl.col(intervention_column) == 1)
                    .get_column("agent_index")
                    .to_list()
                )
                all_non_complying_rows.update(non_complier_rows)

        rows_from_non_intervention = indexed_non_intervention_df.filter(
            pl.col("agent_index").is_in(all_non_complying_rows)
        )
        indexed_intervention_df = indexed_intervention_df.filter(
            ~pl.col("agent_index").is_in(all_non_complying_rows)
        )

        if rows_from_non_intervention.is_empty():
            swapped_intervention_df = indexed_intervention_df
        else:
            swapped_intervention_df = indexed_intervention_df.vstack(
                rows_from_non_intervention
            )

        swapped_intervention_df = swapped_intervention_df.sort("agent_index")

        swapped_intervention_df = swapped_intervention_df.drop("agent_index")

        return swapped_intervention_df

    def _write_debug_files_to_csv(
        self,
        intervention_df: pl.DataFrame,
        swapped_intervention_df: pl.DataFrame,
        non_intervention_df: pl.DataFrame,
        padded_iteration: int,
    ) -> None:
        """
        Write the intervention, swapped intervention, and non-intervention DataFrames to CSV files.

        Parameters
        ----------
        intervention_df : pl.DataFrame
            DataFrame from intervention run
        swapped_intervention_df : pl.DataFrame
            DataFrame with non-compliant rows swapped
        non_intervention_df : pl.DataFrame
            DataFrame from non-intervention run
        padded_iteration : int
            Padded iteration number

        Returns
        -------
        None
        """
        intervention_pandas = intervention_df.to_pandas()
        intervention_pandas.to_csv(
            os.path.join(
                self.simulation_results_path,
                f"intervention_source--{padded_iteration}.csv",
            )
        )
        swapped_intervention_pandas = swapped_intervention_df.to_pandas()
        swapped_intervention_pandas.to_csv(
            os.path.join(
                self.simulation_results_path,
                f"intervention_replaced--{padded_iteration}.csv",
            )
        )
        non_intervention_pandas = non_intervention_df.to_pandas()
        non_intervention_pandas.to_csv(
            os.path.join(
                self.simulation_results_path,
                f"non-intervention_source--{padded_iteration}.csv",
            )
        )

    def _combine_and_collapse(self) -> dict[str, pl.DataFrame]:
        """
        For each parquet file generated by the simulation, total the results
        for a few specific metrics.

        Returns
        -------
        dict
            Dictionary containing the following keys:
            - effectiveness: DataFrame containing the total cost and QALYs for each run
            - yearly_effectiveness: DataFrame containing the total cost and QALYs for each year
            - incidence: DataFrame containing the incidence of chronic and acute events
        """

        effectiveness_data = []
        yearly_effectiveness_data = []
        incidence_data = []

        for filename in glob(os.path.join(self.simulation_results_path, "*.parquet")):
            df = pl.read_parquet(filename)
            run_type = filename.replace(".parquet", "").split("__")[-1]
            intervention = 0 if "non-intervention" in run_type else 1
            data = self._process_data(df, run_type, intervention)

            effectiveness_data.append(data["effectiveness"])
            yearly_effectiveness_data.append(data["yearly_effectiveness"])
            incidence_data.append(data["incidence"])

        effectiveness = self._combine_and_rechunk(effectiveness_data, 'e')
        yearly_effectiveness = self._combine_and_rechunk(yearly_effectiveness_data, 'y')
        incidence = self._combine_and_rechunk(incidence_data, 'i')

        return {
            "effectiveness": effectiveness,
            "yearly_effectiveness": yearly_effectiveness,
            "incidence": incidence,
        }

    def _combine_and_rechunk(self, data: list[pl.DataFrame], xyz) -> pl.DataFrame:
        """
        Combine the DataFrames and rechunk the resulting DataFrame.

        Parameters
        ----------
        data : list
            List of DataFrames to be combined

        Returns
        -------
        pl.DataFrame
            Combined and rechunked DataFrame
        """
        result: pl.DataFrame = data[0]
        for df in data[1:]:
            result = result.vstack(df)
        result.rechunk()

        return result

    def _process_data(
        self, data: pl.DataFrame, run_type: str, is_intervention: int
    ) -> dict[str, pl.DataFrame]:
        """
        Process the simulation results to extract the desired metrics.

        Parameters
        ----------
        data : pl.DataFrame
            DataFrame containing the simulation results
        run_type : str
            Type of run (intervention or non-intervention)
        is_intervention : int
            Whether the run is an intervention run

        Returns
        -------
        dict
            Dictionary containing the following
            - effectiveness: DataFrame containing the total cost and QALYs for a specific run
            - yearly_effectiveness: DataFrame containing the total cost and QALYs for a specific run
            - incidence: DataFrame containing the incidence of chronic and acute events for a specific run
        """
        incidence = self._set_incidence(data, run_type, is_intervention)
        effectiveness_by_year = self._set_yearly_cost_effectiveness(
            data, run_type, is_intervention
        )
        effectiveness = self._set_cost_effectiveness(data, run_type, is_intervention)

        return {
            "effectiveness": effectiveness,
            "yearly_effectiveness": effectiveness_by_year,
            "incidence": incidence,
        }

    def _set_incidence(
        self, df: pl.DataFrame, run_type: str, is_intervention: int
    ) -> pl.DataFrame:
        """
        Set the incidence of chronic and acute events.

        Parameters
        ----------
        df : pl.DataFrame
            DataFrame containing the simulation results
        run_type : str
            Type of run (intervention or non-intervention)
        is_intervention : int
            Whether the run is an intervention run

        Returns
        -------
        pl.DataFrame
            DataFrame containing the incidence of chronic and acute events
        """
        population_size = df.height

        chronic_events, acute_events = self._get_incidence_events()

        chronic_aggregate = unfurl_and_tally_chronic_events(df, chronic_events)
        acute_aggregate = unfurl_and_tally_events(df, acute_events)

        if 'surgery_control_intervention' in self.scenario.keys():
            risk_factors = self._get_risk_factors(True)
            risk_factor_aggregate = unfurl_and_tally_risk_factors(df, risk_factors)
            risk_factor_surgery_aggregate = unfurl_and_tally_risk_factors_surgery(df, risk_factors)
            aggregate = pl.concat([chronic_aggregate, acute_aggregate, risk_factor_aggregate,
                                   risk_factor_surgery_aggregate], how="align")
        else:
            risk_factors = self._get_risk_factors(False)
            risk_factor_aggregate = unfurl_and_tally_risk_factors(df, risk_factors)
            aggregate = pl.concat([chronic_aggregate, acute_aggregate, risk_factor_aggregate], how="align")

        aggregate = aggregate.with_columns(
            group=pl.lit(run_type),
            intervention=pl.lit(is_intervention),
            person_years=sum(df["lifespan"]),
            count_surviving=population_size - pl.col("cumulative_death"),
        )

        aggregate = self._order_columns(aggregate)

        return aggregate

    def _get_incidence_events(self) -> tuple[list[str], list[str]]:
        """
        Get the chronic and acute events for the given diabetes type.

        Returns
        -------
        tuple
            Tuple containing the chronic and acute events
        """
        if self.scenario["diabetes_type"] == "t2d":
            chronic_events = [
                "chf",
                "microalbuminuria",
                "macroalbuminuria",
                "amputation",
                "blindness",
                "dialysis",
                "neurop",
                "egfr_30",
                "egfr_60",
                "laser_retina",
                # "depression"
            ]
            acute_events = [
                "stroke",
                "angina",
                "mi",
                "revasc",
                "hypoglycemia_any",
                "hypoglycemia_medical",
                "ulcer",
                "death",
            ]
        elif self.scenario["diabetes_type"] in ["pre", "screen"]:
            chronic_events = [
                "chf",
                "microalbuminuria",
                "macroalbuminuria",
                "amputation",
                "blindness",
                "dialysis",
                "neurop",
                "egfr_30",
                "egfr_60",
                "laser_retina",
                "diabetes",
                # "depression"
            ]
            acute_events = [
                "stroke",
                "angina",
                "mi",
                "revasc",
                "hypoglycemia_any",
                "hypoglycemia_medical",
                "ulcer",
                "death",
            ]
        else:
            chronic_events = [
                "amputation",
                "csme",
                "dka",
                "dpn",
                "esrd",
                "gfr",
                "microalbuminuria",
                "macroalbuminuria",
                "npdr",
                "pdr",
                "ulcer",
                # "depression"
            ]
            acute_events = ["cvd", "cvd_mace", "cvd_non_mace", "hypoglycemia", "death"]

        return chronic_events, acute_events

    def _get_risk_factors(self, has_surgery) -> list[str]:
        """
        Get the chronic and acute events for the given diabetes type.

        Returns
        -------
        tuple
            Tuple containing the chronic and acute events
        """
        if self.scenario["diabetes_type"] != "t1d":
            if has_surgery and self.scenario["diabetes_type"] == "t2d":
                risk_factors = [
                    "bmi",
                    "hba1c",
                    "hdl",
                    "ldl",
                    "sbp",
                    "serum_creatinine",
                    "trig",
                    "remission",
                    "relapse"
                ]
            else:
                risk_factors = [
                    "bmi",
                    "hba1c",
                    "hdl",
                    "ldl",
                    "sbp",
                    "serum_creatinine",
                    "trig"
                ]
        else:
            risk_factors = [
                "bmi",
                "dbp",
                "hba1c",
                "hdl",
                "hr",
                "hypertension",
                "ldl",
                "sbp",
                "trig"
            ]

        return risk_factors

    def _set_yearly_cost_effectiveness(
        self, df: pl.DataFrame, run_type: str, is_intervention: int
    ) -> pl.DataFrame:
        """
        Set the yearly cost-effectiveness metrics.

        Parameters
        ----------
        df : pl.DataFrame
            DataFrame containing the simulation results
        run_type : str
            Type of run (intervention or non-intervention)
        is_intervention : int
            Whether the run is an intervention run

        Returns
        -------
        pl.DataFrame
            DataFrame containing the yearly cost-effectiveness metrics
        """
        aggregate = unfurl_and_tally_events(df, ["overall_cost", "qaly"])

        aggregate = aggregate.with_columns(
            pl.lit(run_type).alias("group"),
            pl.lit(is_intervention).alias("intervention"),
        )
        aggregate = aggregate.rename(
            {"cumulative_overall_cost": "cumulative_health_cost"}
        )

        aggregate = self._order_columns(aggregate)

        return aggregate

    def _set_cost_effectiveness(
        self, df: pl.DataFrame, run_type: str, is_intervention: int
    ) -> pl.DataFrame:
        """
        Set the cost-effectiveness metrics.

        Parameters
        ----------
        df : pl.DataFrame
            DataFrame containing the simulation results
        run_type : str
            Type of run (intervention or non-intervention)
        is_intervention : int
            Whether the run is an intervention run

        Returns
        -------
        pl.DataFrame
            DataFrame containing the cost-effectiveness metrics
        """
        cost_effectiveness = df.with_columns(
            total_cost=pl.col("overall_cost").list.sum(),
            total_health_cost=pl.col("health_cost").list.sum(),
            total_event_cost=pl.col("event_cost").list.sum(),
            total_intervention_cost=pl.col("intervention_cost").list.sum(),
            qaly_value=pl.col("qaly").list.sum(),
        )

        if self.scenario["diabetes_type"] in ["pre", "screen"]:
            cost_effectiveness = cost_effectiveness.with_columns(
                remaining_life_years=pl.col("age") - pl.col("age_entry_fixed")
            )
        else:
            cost_effectiveness = cost_effectiveness.with_columns(
                remaining_life_years=pl.col("age") - pl.col("age_entry")
            )

        cost_effectiveness_dict = {
            "group": run_type,
            "intervention": is_intervention,
            "total_cost": round(cost_effectiveness["total_cost"].sum(), 2),
            "total_health_cost": round(
                cost_effectiveness["total_health_cost"].sum(), 2
            ),
            "total_event_cost": round(cost_effectiveness["total_event_cost"].sum(), 2),
            "total_intervention_cost": round(
                cost_effectiveness["total_intervention_cost"].sum(), 2
            ),
            "qaly": round(cost_effectiveness["qaly_value"].sum(), 4),
            "remaining_life_years": round(
                cost_effectiveness["remaining_life_years"].sum(), 2
            ),
        }

        if self.scenario["diabetes_type"] == "screen":
            cost_effectiveness = cost_effectiveness.with_columns(
                total_screening_cost=pl.col("screening_cost").list.sum()
            )
            cost_effectiveness_dict["total_screening_cost"] = round(
                cost_effectiveness["total_screening_cost"].sum(), 2
            )
            cost_effectiveness_dict["total_screening_cost"] = float(cost_effectiveness_dict["total_screening_cost"])

        return pl.DataFrame(cost_effectiveness_dict)

    def _order_columns(self, df: pl.DataFrame) -> pl.DataFrame:
        """
        Order the columns in the DataFrame so that the first 3 columns are group, intervention, step.

        Parameters
        ----------
        df : pl.DataFrame
            DataFrame to be ordered

        Returns
        -------
        pl.DataFrame
            DataFrame with ordered columns
        """
        columns = df.columns
        group_index = columns.index("group")
        intervention_index = columns.index("intervention")
        columns.insert(0, columns.pop(group_index))
        columns.insert(1, columns.pop(intervention_index))

        return df.select(columns)

    def _create_data_tables(self, combined_dataframes: dict[str, pl.DataFrame]) -> None:
        """
        Create the CSV data tables.

        Parameters
        ----------
        combined_dataframes : dict
            Dictionary containing the combined DataFrames

        Returns
        -------
        None
        """
        individual_incidences, cumulative_incidences = self._record_incidence(
            combined_dataframes["incidence"]
        )
        cumulative_incidences.write_csv(
            os.path.join(self.analysis_output_path, "cumulative incidence.csv")
        )
        individual_incidences.write_csv(
            os.path.join(self.analysis_output_path, "incidence.csv")
        )

        prevalence, mean_prevalence = self._record_prevalence(
            combined_dataframes["incidence"]
        )
        prevalence.write_csv(os.path.join(self.analysis_output_path, "prevalence.csv"))
        mean_prevalence.write_csv(
            os.path.join(self.analysis_output_path, "mean_prevalence.csv")
        )

        (
            cost_effectiveness_transposed,
            mean_cost_effectiveness,
            cost_effectiveness,
        ) = self._record_cost_effectiveness(combined_dataframes["effectiveness"])

        # UI expects only value columns; drop the cost_type column
        cost_effectiveness_transposed.drop_in_place("cost_type")

        cost_effectiveness_transposed.write_csv(
            os.path.join(self.analysis_output_path, "cost_effectiveness transposed.csv")
        )
        mean_cost_effectiveness.write_csv(
            os.path.join(self.analysis_output_path, "mean cost_effectiveness.csv")
        )
        cost_effectiveness.write_csv(
            os.path.join(self.analysis_output_path, "cost_effectiveness.csv")
        )

        (
            per_person_cost_effectiveness,
            per_person_transposed,
        ) = self._record_yearly_cost_effectiveness(
            combined_dataframes["yearly_effectiveness"]
        )
        per_person_cost_effectiveness.write_csv(
            os.path.join(self.analysis_output_path, "per_person_cost_effectiveness.csv")
        )
        per_person_transposed.write_csv(
            os.path.join(
                self.analysis_output_path,
                "per_person_cost_effectiveness transposed.csv",
            )
        )

    def _record_incidence(self, df: pl.DataFrame) -> tuple[pl.DataFrame, pl.DataFrame]:
        """
        Record the incidence of chronic and acute events.

        Parameters
        ----------
        df : pl.DataFrame
            DataFrame containing the incidence of chronic and acute events for a given run

        Returns
        -------
        tuple
            Tuple containing the individual and cumulative incidence DataFrames
        """
        incidence = df.drop("person_years")

        # cumulative_columns = [col for col in incidence.columns if "cumulative" in col]
        cumulative_columns = [col for col in incidence.columns if "cumulative" in col or "mean" in col or "sum" in col]
        cumulative_columns.append("count_surviving")
        individual_columns = [
            col for col in incidence.columns if col not in cumulative_columns
        ]

        cumulative_incidences = incidence.select(["group", "step", *cumulative_columns])
        cumulative_incidences.columns = [
            col.replace("cumulative_", "") for col in cumulative_incidences.columns
        ]
        individual_incidences = incidence.select(individual_columns)

        return individual_incidences, cumulative_incidences

    def _record_prevalence(
        self, df: pl.DataFrame
    ) -> tuple[pl.DataFrame, pl.DataFrame, pl.DataFrame]:
        """
        Record the prevalence of chronic and acute events.

        Parameters
        ----------
        df : pl.DataFrame
            DataFrame containing the incidence of chronic and acute events for a given run

        Returns
        -------
        tuple
            Tuple containing the individual and cumulative prevalence DataFrames
        """
        # This polars operation takes the data, where a row is a timestep for each group,
        # and compresses it so that there is one row per group, with the sum of each event
        # over all timesteps. It then calculates the mean person years for each group and
        # gets the first value for each group (1 for intervention, 0 for non-intervention).
        prevalence = df.group_by("group", maintain_order=True).agg(
            [
                *[pl.col(event).sum().alias(event) for event in self.events],
                pl.col("person_years").mean().alias("person_years"),
                pl.col("intervention").first().alias("intervention"),
            ]
        )

        sorted_columns = sorted(
            [col for col in prevalence.columns if col not in ["group", "intervention"]]
        )
        sorted_columns = ["group", "intervention", *sorted_columns]

        prevalence = prevalence.select(sorted_columns)
        mean_prevalence = prevalence.drop("group")
        mean_prevalence = mean_prevalence.group_by(
            "intervention", maintain_order=True
        ).mean()

        return prevalence, mean_prevalence

    def _record_cost_effectiveness(
        self, df: pl.DataFrame
    ) -> tuple[pl.DataFrame, pl.DataFrame, pl.DataFrame]:
        """
        Record the cost-effectiveness metrics.

        Parameters
        ----------
        df : pl.DataFrame
            DataFrame containing the cost-effectiveness metrics

        Returns
        -------
        tuple
            Tuple containing the individual, transposed, and mean cost-effectiveness DataFrames
        """
        population_size = self.scenario["size"]
        cost_effectiveness = df.with_columns(
            pl.col("group").str.split(by="--").list.last().alias("run")
        )
        cost_effectiveness = cost_effectiveness.sort(["run", "intervention"])

        new_rows = [
            self._calculate_cost_effectiveness_increments(run[0], data, population_size)
            for run, data in cost_effectiveness.group_by(["run"], maintain_order=True)
        ]

        cost_effectiveness = pl.DataFrame(new_rows)
        cost_effectiveness_transposed = cost_effectiveness.drop("run").transpose(
            include_header=True,
            header_name="cost_type",
            column_names=self._transposed_column_name_generator(),
        )

        alt_icer_name = "ICER: mean inc Cost / mean inc QALY"

        mean_cost_effectiveness = cost_effectiveness.drop("run").mean()
        mean_cost_effectiveness = mean_cost_effectiveness.with_columns(
            pl.when(pl.col("QALY increment") != 0.0)
            .then((pl.col("Cost increment") / pl.col("QALY increment")).round(4))
            .otherwise(pl.lit(0.0))
            .alias(alt_icer_name)
        )

        column_order = self._get_cost_effectiveness_column_order()

        # `alt_icer_name` is calculated separately (all other values are automatically averaged) so
        # make sure only the mean row has a value
        cost_effectiveness = cost_effectiveness.with_columns(
            pl.lit(np.nan).alias(alt_icer_name)
        )
        cost_effectiveness = cost_effectiveness.select(column_order)
        cost_effectiveness = cost_effectiveness.vstack(
            mean_cost_effectiveness.with_columns(run=pl.lit("mean")).select(
                column_order
            )
        )

        return (
            cost_effectiveness_transposed,
            mean_cost_effectiveness,
            cost_effectiveness,
        )

    def _calculate_cost_effectiveness_increments(
        self, run: str, run_group: pl.DataFrame, population_size: int
    ) -> dict[str, float]:
        """
        Calculate the cost-effectiveness increments for a given run.

        Parameters
        ----------
        run : str
            Run name
        run_group : pl.DataFrame
            DataFrame containing the results for a specific run
        population_size : int
            Size of the population

        Returns
        -------
        dict
            Dictionary containing the cost-effectiveness increments
        """
        non_intervention_cost, intervention_cost = run_group["total_cost"].to_list()
        non_intervention_health_cost, intervention_health_cost = run_group[
            "total_health_cost"
        ].to_list()
        non_intervention_event_cost, intervention_event_cost = run_group[
            "total_event_cost"
        ].to_list()
        non_intervention_intervention_cost, intervention_intervention_cost = run_group[
            "total_intervention_cost"
        ].to_list()
        non_intervention_qaly, intervention_qaly = run_group["qaly"].to_list()
        non_intervention_years, intervention_years = run_group[
            "remaining_life_years"
        ].to_list()

        if self.scenario["diabetes_type"] == "screen":
            _, intervention_screening_cost = run_group["total_screening_cost"].to_list()

        row_data = {
            "run": run,
            "Total cost non-intervention": round(
                non_intervention_cost / population_size, 2
            ),
            "QALY non-intervention": round(non_intervention_qaly / population_size, 4),
            "Total cost intervention": round(intervention_cost / population_size, 2),
            "QALY intervention": round(intervention_qaly / population_size, 4),
        }

        cost_increment = (intervention_cost - non_intervention_cost) / population_size
        row_data["Cost increment"] = round(cost_increment, 2)
        qaly_incrememnt = (intervention_qaly - non_intervention_qaly) / population_size
        row_data["QALY increment"] = round(qaly_incrememnt, 4)

        if row_data["QALY increment"]:
            icer = row_data["Cost increment"] / row_data["QALY increment"]
            row_data["ICER"] = round(icer, 2)
        else:
            row_data["ICER"] = 0.0

        row_data["Remaining LY non-intervention"] = round(
            non_intervention_years / population_size, 4
        )
        row_data["Remaining LY intervention"] = round(
            intervention_years / population_size, 4
        )
        row_data["LY increment"] = round(
            (intervention_years - non_intervention_years) / population_size, 4
        )

        row_data["Treatment costs - non-intervention"] = round(
            non_intervention_health_cost / population_size, 2
        )
        row_data["Complication costs - non-intervention"] = round(
            non_intervention_event_cost / population_size, 2
        )
        row_data["Intervention costs - non-intervention"] = round(
            non_intervention_intervention_cost / population_size, 2
        )
        row_data["Treatment costs - intervention"] = round(
            intervention_health_cost / population_size, 2
        )
        row_data["Complication costs - intervention"] = round(
            intervention_event_cost / population_size, 2
        )
        row_data["Intervention costs - intervention"] = round(
            intervention_intervention_cost / population_size, 2
        )

        if self.scenario["diabetes_type"] == "screen":
            row_data["Screening costs - non-intervention"] = 0.0
            row_data["Screening costs - intervention"] = round(
                intervention_screening_cost / population_size, 2
            )
            row_data["Intervention costs - intervention"] += row_data[
                "Screening costs - intervention"
            ]

        return row_data

    def _transposed_column_name_generator(self):
        """
        Generate the column names for the transposed cost-effectiveness DataFrame.

        Yields
        -------
        str
            Column name for the transposed cost-effectiveness DataFrame
        """
        base_name = "run "
        count = 1
        while True:
            yield f"{base_name}{count}"
            count += 1

    def _get_cost_effectiveness_column_order(self) -> list[str]:
        """
        Get the column order for the cost-effectiveness metrics.

        Returns
        -------
        list
            List of column names
        """
        if self.scenario["diabetes_type"] == "screen":
            return [
                "run",
                "Total cost non-intervention",
                "Treatment costs - non-intervention",
                "Complication costs - non-intervention",
                "Intervention costs - non-intervention",
                "Screening costs - non-intervention",
                "QALY non-intervention",
                "Total cost intervention",
                "Treatment costs - intervention",
                "Complication costs - intervention",
                "Intervention costs - intervention",
                "Screening costs - intervention",
                "QALY intervention",
                "Cost increment",
                "QALY increment",
                "ICER",
                "ICER: mean inc Cost / mean inc QALY",
                "Remaining LY non-intervention",
                "Remaining LY intervention",
                "LY increment",
            ]

        return [
            "run",
            "Total cost non-intervention",
            "Treatment costs - non-intervention",
            "Complication costs - non-intervention",
            "Intervention costs - non-intervention",
            "QALY non-intervention",
            "Total cost intervention",
            "Treatment costs - intervention",
            "Complication costs - intervention",
            "Intervention costs - intervention",
            "QALY intervention",
            "Cost increment",
            "QALY increment",
            "ICER",
            "ICER: mean inc Cost / mean inc QALY",
            "Remaining LY non-intervention",
            "Remaining LY intervention",
            "LY increment",
        ]

    def _record_yearly_cost_effectiveness(
        self, df: pl.DataFrame
    ) -> tuple[pl.DataFrame, pl.DataFrame]:
        """
        Record the yearly cost-effectiveness metrics.

        Parameters
        ----------
        df : pl.DataFrame
            DataFrame containing the yearly cost-effectiveness metrics

        Returns
        -------
        tuple
            Tuple containing the individual and transposed yearly cost-effectiveness DataFrames
        """
        population_size = self.scenario["size"]
        yearly_cost_effectiveness = df.with_columns(
            pl.col("group").str.split(by="--").list.last().alias("run")
        )
        yearly_cost_effectiveness = yearly_cost_effectiveness.sort(
            ["run", "intervention", "step"]
        )

        new_rows = [
            self._calculate_yearly_cost_effectiveness_increments(
                run, data, population_size
            )
            for run, data in yearly_cost_effectiveness.group_by(
                ["run", "step"], maintain_order=True
            )
        ]

        yearly_cost_effectiveness = pl.DataFrame(new_rows)

        yearly_cost_effectiveness = self._fix_uneven_runs(yearly_cost_effectiveness)

        yearly_cost_effectiveness = yearly_cost_effectiveness.with_columns(
            pl.when(pl.col("cumulative_cost_increment_by_person") != 0.0)
            .then(
                (
                    pl.col("cumulative_qaly_increment_by_person")
                    / pl.col("cumulative_cost_increment_by_person")
                ).round(4)
            )
            .otherwise(pl.lit(0.0))
            .alias("icer")
        )

        per_person_cost_effectiveness = yearly_cost_effectiveness.select(
            YEARLY_COST_EFFECTIVENESS_COLUMN_ORDER
        )

        iterations = self.scenario["iterations"]
        years_dict = {
            int(group["run"]): group["len"]
            for group in per_person_cost_effectiveness.group_by(
                "run", maintain_order=True
            )
            .len()
            .to_dicts()
        }
        if self.scenario["time_horizon"] == "max_steps":
            years_dict = {
                iteration: iterations for iteration in range(1, iterations + 1)
            }

        columns = []
        for run, years in years_dict.items():
            columns.extend(f"run: {run} - year: {year}" for year in range(1, years + 1))

        per_person_transposed = per_person_cost_effectiveness.drop(
            ["run", "year"]
        ).transpose(include_header=True, header_name="value_name", column_names=columns)

        return per_person_cost_effectiveness, per_person_transposed

    def _calculate_yearly_cost_effectiveness_increments(
        self, group: tuple[str], run_group: pl.DataFrame, population_size: int
    ) -> dict[str, str | float | None]:
        """
        Calculate the yearly cost-effectiveness increments for a given run.

        Parameters
        ----------
        group : tuple[str]
            (Run name, step)
        run_group : pl.DataFrame
            DataFrame containing the results for a specific run

        Returns
        -------
        dict
            Dictionary containing the yearly cost-effectiveness increments
        """
        group_names = (
            run_group["group"].unique().str.split(by="--").list.first().to_list()
        )
        intervention_cost = 0.0
        intervention_qaly = 0.0
        non_intervention_cost = 0.0
        non_intervention_qaly = 0.0
        intervention_cost_cumulative = 0.0
        intervention_qaly_cumulative = 0.0
        non_intervention_cost_cumulative = 0.0
        non_intervention_qaly_cumulative = 0.0

        df = run_group.select(
            [
                "intervention",
                "overall_cost",
                "cumulative_health_cost",
                "qaly",
                "cumulative_qaly",
            ]
        )

        if "non-intervention" in group_names:
            (
                _,
                non_intervention_cost,
                non_intervention_cost_cumulative,
                non_intervention_qaly,
                non_intervention_qaly_cumulative,
            ) = df.row(by_predicate=pl.col("intervention") == 0)

        if "intervention" in group_names:
            (
                _,
                intervention_cost,
                intervention_cost_cumulative,
                intervention_qaly,
                intervention_qaly_cumulative,
            ) = df.row(by_predicate=pl.col("intervention") == 1)

        cumulative_cost_non_intervention_by_person = (
            round(non_intervention_cost_cumulative, 2) / population_size
        )
        cumulative_cost_intervention_by_person = (
            round(intervention_cost_cumulative, 2) / population_size
        )
        cumulative_qaly_non_intervention_by_person = (
            round(non_intervention_qaly_cumulative, 4) / population_size
        )
        cumulative_qaly_intervention_by_person = (
            round(intervention_qaly_cumulative, 4) / population_size
        )
        cumulative_cost_increment_by_person = (
            cumulative_cost_intervention_by_person
            - cumulative_cost_non_intervention_by_person
        )
        cumulative_qaly_increment_by_person = (
            cumulative_qaly_intervention_by_person
            - cumulative_qaly_non_intervention_by_person
        )

        # Setting these to None for when we need to fix the uneven run
        if (
            cumulative_cost_intervention_by_person == 0.0
            or cumulative_cost_non_intervention_by_person == 0.0
        ):
            cumulative_cost_increment_by_person = None
        if (
            cumulative_qaly_intervention_by_person == 0.0
            or cumulative_qaly_non_intervention_by_person == 0.0
        ):
            cumulative_qaly_increment_by_person = None

        # Setting some of the 0 values to None for when we need to fix the uneven run
        return {
            "run": group[0],
            "year": group[1],
            "intervention_cost_cumulative": intervention_cost_cumulative,
            "non_intervention_cost_cumulative": non_intervention_cost_cumulative,
            "intervention_qaly_cumulative": intervention_qaly_cumulative,
            "non_intervention_qaly_cumulative": non_intervention_qaly_cumulative,
            "cost_non_intervention_by_person": round(non_intervention_cost, 2)
            / population_size,
            "qaly_non_intervention_by_person": round(non_intervention_qaly, 4)
            / population_size,
            "cost_intervention_by_person": round(intervention_cost, 2)
            / population_size,
            "qaly_intervention_by_person": round(intervention_qaly, 4)
            / population_size,
            "cost_increment_by_person": (intervention_cost - non_intervention_cost)
            / population_size,
            "qaly_increment_by_person": (intervention_qaly - non_intervention_qaly)
            / population_size,
            "cumulative_cost_non_intervention_by_person": cumulative_cost_non_intervention_by_person
            if cumulative_cost_non_intervention_by_person > 0.0
            else None,
            "cumulative_cost_intervention_by_person": cumulative_cost_intervention_by_person
            if cumulative_cost_intervention_by_person > 0.0
            else None,
            "cumulative_qaly_non_intervention_by_person": cumulative_qaly_non_intervention_by_person
            if cumulative_qaly_non_intervention_by_person > 0.0
            else None,
            "cumulative_qaly_intervention_by_person": cumulative_qaly_intervention_by_person
            if cumulative_qaly_intervention_by_person > 0.0
            else None,
            "cumulative_cost_increment_by_person": cumulative_cost_increment_by_person,
            "cumulative_qaly_increment_by_person": cumulative_qaly_increment_by_person,
        }

    def _fix_uneven_runs(self, df: pl.DataFrame) -> pl.DataFrame:
        """
        Fix uneven runs by filling null values.

        For the columns in [
        `cumulative_cost_intervention_by_person`,
        `cumulative_cost_non_intervention_by_person`,
        `cumulative_qaly_intervention_by_person`,
        `cumulative_qaly_non_intervention_by_person`
        ], fill the null values with the value from the previous row.
        For the columns in [
        `cumulative_cost_increment_by_person`,
        `cumulative_qaly_increment_by_person`
        ], fill the null values with the difference between the appropriate
        intervention - non-intervention columns above.

        Parameters
        ----------
        df : pl.DataFrame
            DataFrame to be fixed

        Returns
        -------
        pl.DataFrame
            Fixed DataFrame
        """
        first_columns_to_fix = [
            "cumulative_cost_intervention_by_person",
            "cumulative_cost_non_intervention_by_person",
            "cumulative_qaly_intervention_by_person",
            "cumulative_qaly_non_intervention_by_person",
        ]
        fixed_df = df.with_columns(
            pl.col(column).fill_null(strategy="forward")
            for column in first_columns_to_fix
        )
        fixed_df = fixed_df.with_columns(
            cumulative_cost_increment_by_person=(
                pl.col("cumulative_cost_intervention_by_person")
                - pl.col("cumulative_cost_non_intervention_by_person")
            ),
            cumulative_qaly_increment_by_person=(
                pl.col("cumulative_qaly_intervention_by_person")
                - pl.col("cumulative_qaly_non_intervention_by_person")
            ),
        )

        return fixed_df

    def cleanup(self) -> None:
        """
        Clean up the simulation files.

        Returns
        -------
        None
        """

        # if a user wants to save a population data set this directory must not be purged
        if not self.scenario['save_items_on_run'][0]['save_population']:
            try:
                shutil.rmtree(self.population_results_path)
            except FileNotFoundError:
                logging.warn(f"{self.population_results_path} does not exist.")
            except Exception as e:
                logging.error(f"Error cleaning up {self.population_results_path}: {e}")

        try:
            shutil.rmtree(self.simulation_results_path)
        except FileNotFoundError:
            logging.warn(f"{self.simulation_results_path} does not exist.")
        except Exception as e:
            logging.error(f"Error cleaning up {self.simulation_results_path}: {e}")
